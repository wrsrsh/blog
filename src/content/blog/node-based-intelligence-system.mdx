
---
title: "A Graph-Based Approach to Structured LLM Workflows"
description: "Design notes on implementing a node-based intelligence system."
pubDate: "2026-02-16"
---
import Latex from '../../components/Latex.astro'

This document describes the design of a node-based execution system for large language model (LLM) workflows. Instead of organizing reasoning as a linear chain of prompts, we model the system as a directed graph whose nodes represent typed reasoning units and whose edges encode deterministic routing rules. The objective is not to increase model capability, but to improve reliability, inspectability, and structural clarity under conditional complexity.

Many LLM systems begin as a single prompt. Over time, conditional logic is appended: tone shifts, branching behavior, state tracking, personalization layers. Eventually, the prompt encodes both inference and control flow in natural language.

The result is difficult to reason about. State is implicit. Execution order is unclear. Debugging requires reading prose rather than examining structure.

We sought a representation in which reasoning could be decomposed into explicit units.

We represent the workflow as a directed graph:

<Latex formula='G = (V, E)' />

where:

- <Latex formula='V' inline /> is the set of nodes  
- <Latex formula='E \subseteq V \times V' inline /> is the set of directed edges  

Each node <Latex formula='v \in V' inline /> has a type:

- `classifier`
- `transformer`
- `phase`
- `stage`
- `choice`

Execution is defined as traversal starting from a root node (a node with no incoming edges) and proceeding until a terminal `stage` node is reached.

```ts
while (currentNode) {
  switch (currentNode.data.type) {
    case "classifier":
      currentNode = await handleClassifier(...)
      break
    case "transformer":
      currentNode = await handleTransformer(...)
      break
    case "phase":
      currentNode = advancePhase(...)
      break
    case "stage":
      return await generateStage(...)
  }
}
````

The traversal loop itself contains minimal domain logic. Behavior emerges from the graph’s structure.

---

### 3. Classifiers as Structured Functions

A classifier node maps contextual input <Latex formula='X' inline /> to structured state <Latex formula='S' inline />:

<Latex formula='f_{\text{classifier}} : X \rightarrow S' />

The output schema <Latex formula='S' inline /> is defined explicitly and enforced at runtime.

```ts
const classificationShape: Record<string, ZodTypeAny> = {}

for (const def of relevantOutputDefinitions) {
  classificationShape[def.key] = outputDefinitionToZodSchema(def)
}

const classifierResponseSchema = z.object({
  classification: z.object(classificationShape)
})
```

The model must return JSON conforming to this schema. This transforms natural language inference into a constrained mapping from input to typed variables.

Edges from classifier nodes encode predicates:

<Latex formula='\text{edge}(v_i, v_j) \text{ is valid iff } \forall k,\; S[k] = c_k' />

In code:

```ts
function evaluateFilter(filters, outputData) {
  for (const filter of filters) {
    if (outputData[filter.key] !== filter.value) {
      return false
    }
  }
  return true
}
```

The model determines <Latex formula='S' inline />, but routing remains deterministic.

---

### 4. Phases as State Transitions

We treat conversational phases as explicit nodes rather than metadata labels.

Let <Latex formula='P \subseteq V' inline /> denote the set of phase nodes. We compute a parent mapping:

<Latex formula='\pi : P \rightarrow P \cup \{\varnothing\}' />

where <Latex formula='\pi(p)' inline /> is the direct parent phase of <Latex formula='p' inline />, if any.

This mapping is derived via breadth-first traversal of the graph.

```ts
export function computePhaseParentMap(nodes, edges) {
  // BFS to determine direct parent-child relationships
}
```

If the ordered phase sequence is:

<Latex formula='p_1 \rightarrow p_2 \rightarrow \dots \rightarrow p_n' />

and the current phase is <Latex formula='p_i' inline />, allowable next phases are restricted to:

<Latex formula='\{ p_{i+1}, \dots, p_n \} \cup P_{\text{unordered}}' />

This constraint converts the workflow into a bounded state machine.

---

### 5. Transformers as Intermediate Mappings

Transformer nodes compute derived representations:

<Latex formula='f_{\text{transformer}} : X \rightarrow T' />

where <Latex formula='T' inline /> is an intermediate artifact (e.g., summary, extracted features, normalized context).

Outputs can be injected into downstream nodes:

```ts
function getTransformerContextForNode(node, transformerOutputs) {
  return node.data.transformerInputs
    ?.map(id => transformerOutputs[id])
    .join("\n\n---\n\n") ?? ""
}
```

This modularization prevents excessive prompt entanglement by separating interpretation from generation.

---

### 6. Stage Nodes

Stage nodes produce final messages:

<Latex formula='f_{\text{stage}} : (X, S, T) \rightarrow M' />

where <Latex formula='M' inline /> is a set of output messages.

Outputs are schema-constrained:

```ts
z.object({
  messages: z.array(z.string()),
  reasoning: z.string()
})
```

The constraint reduces format variance and simplifies downstream handling.

---

### 7. Provider Abstraction

Model provider selection is separated from graph logic:

```ts
export function getProviderFromModelId(modelId: string) {
  if (modelId.includes("gemini")) return "google"
  if (modelId.includes("cerebras")) return "cerebras"
  return "openai"
}
```

This abstraction isolates infrastructure decisions from reasoning structure.

---

### 8. Observability

Each node execution is wrapped in a tracing context:

```ts
await startActiveObservation(
  `Classifier Node • ${nodeTitle}`,
  async (observation) => {
    observation.update({ input, metadata })
    const result = await generateClassification(...)
    observation.update({ output: result })
  }
)
```

Observability ensures that probabilistic inference steps remain inspectable.

---

### 9. Conclusion

By modeling reasoning as graph traversal with typed nodes and deterministic routing, we externalize control flow and make state explicit.

The system does not attempt to alter the probabilistic nature of LLM inference. Instead, it constrains and contextualizes that inference within a well-defined execution structure.

The resulting architecture prioritizes clarity over ambition and structure over narrative complexity.
